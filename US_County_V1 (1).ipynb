{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#api key: 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\n",
        "\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "6NAIqnKOmCYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas tqdm pgeocode python-dotenv openai"
      ],
      "metadata": {
        "id": "9pczEz45lz-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ccb45c-8ddc-41cf-bb65-34f32551c316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pgeocode in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pgeocode) (2.32.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pgeocode) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pgeocode) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1nRY3oV_Car",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "27472be4-337e-4bda-c108-ede1e0a8dc40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3235 U.S. counties.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Estimating: 100%|██████████| 3235/3235 [23:08<00:00,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 3235 rows to us_county_llm_estimates.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3408435b-94d1-4a55-b059-978dd4005c7d\", \"us_county_llm_estimates.csv\", 118474)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os, re, json\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any, List\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "AGE = 38  # average age of first-time homeowner\n",
        "OUTPUT_CSV = \"us_county_llm_estimates.csv\"\n",
        "\n",
        "# API Setup\n",
        "load_dotenv()\n",
        "API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "BASE_URL = \"https://api.groq.com/openai/v1\"\n",
        "MODEL = \"openai/gpt-oss-120b\"\n",
        "\n",
        "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
        "\n",
        "SYSTEM_MSG = (\n",
        "    \"You are a careful estimator. \"\n",
        "    \"For each county, produce distinct outputs. \"\n",
        "    \"Distribute loan_confidence across 0.000–0.999, estimated_credit_score across 550–780. \"\n",
        "    \"Use the full range: some values should be low, some medium, some high. \"\n",
        "    \"Do not cluster everything around one number. \"\n",
        "    \"Ensure consecutive counties are not identical. \"\n",
        "    \"Always return only strict JSON with exactly these three keys: \"\n",
        "    '{\"loan_confidence\": <float>, \"estimated_credit_score\": <int>, \"area_median_income\": <int>}.'\n",
        ")\n",
        "\n",
        "def build_user_prompt(county_name: str, county_fips: str, age: int) -> str:\n",
        "    return f\"\"\"\n",
        "Task: Given a U.S. county and its FIPS code and a fixed applicant age, output three numeric fields estimating:\n",
        "1) loan_confidence: a float between 0 and 1 for how confident a typical lender should be about approving a standard home loan for an average applicant in this county.\n",
        "2) estimated_credit_score: an integer from 300 to 850 for a typical applicant in this county.\n",
        "3) area_median_income: an integer (USD) for median household income in this county.\n",
        "\n",
        "Inputs:\n",
        "- County: {county_name}\n",
        "- FIPS code: {county_fips}\n",
        "- Age: {age}\n",
        "\n",
        "Assumptions:\n",
        "- No personal credit history provided; assume an average applicant in the area.\n",
        "- Use broad socioeconomic priors, not exact facts. Do not output null.\n",
        "\n",
        "Output requirements:\n",
        "- Output strictly valid JSON with exactly these three keys and no others:\n",
        "  {{\"loan_confidence\": <float 0..1>, \"estimated_credit_score\": <int 300..850>, \"area_median_income\": <int>}}\n",
        "- No additional text, no markdown, no commentary.\n",
        "\"\"\"\n",
        "\n",
        "JSON_ONLY = {\"type\": \"json_object\"}\n",
        "\n",
        "@dataclass\n",
        "class Estimation:\n",
        "    county_fips: str\n",
        "    county: str\n",
        "    age: int\n",
        "    loan_confidence: float\n",
        "    estimated_credit_score: int\n",
        "    area_median_income: int\n",
        "\n",
        "class ParseError(Exception):\n",
        "    pass\n",
        "\n",
        "def extract_json(text: str) -> Dict[str, Any]:\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
        "        if not m:\n",
        "            raise ParseError(f\"Could not find JSON object in: {text[:200]!r}\")\n",
        "        return json.loads(m.group(0))\n",
        "\n",
        "def call_llm(county_name: str, county_fips: str, age: int) -> Dict[str, Any]:\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        temperature=0.5,\n",
        "        max_tokens=700,  #more room than before\n",
        "        response_format=JSON_ONLY,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
        "            {\"role\": \"user\", \"content\": build_user_prompt(county_name, county_fips, age)},\n",
        "        ],\n",
        "    )\n",
        "    text = resp.choices[0].message.content\n",
        "    return extract_json(text)\n",
        "\n",
        "def get_us_counties() -> pd.DataFrame:\n",
        "    # Census file of all counties and FIPS\n",
        "    url = \"https://www2.census.gov/geo/docs/reference/codes/files/national_county.txt\"\n",
        "    df = pd.read_csv(\n",
        "        url,\n",
        "        header=None,\n",
        "        dtype=str,\n",
        "        names=[\"state\", \"state_fips\", \"county_fips\", \"county_name\", \"class_fips\"],\n",
        "    )\n",
        "    df[\"county_fips_full\"] = df[\"state_fips\"].str.zfill(2) + df[\"county_fips\"].str.zfill(3)\n",
        "    df[\"county_display\"] = df[\"county_name\"].str.title() + \", \" + df[\"state\"]\n",
        "    return df[[\"county_fips_full\", \"county_display\"]]\n",
        "\n",
        "def main():\n",
        "    counties = get_us_counties()\n",
        "    print(f\"Found {len(counties)} U.S. counties.\")\n",
        "    out_rows = []\n",
        "\n",
        "    max_workers = 2  # careful with rate limits\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = {\n",
        "            executor.submit(call_llm, row[\"county_display\"], row[\"county_fips_full\"], AGE): row\n",
        "            for _, row in counties.iterrows()\n",
        "        }\n",
        "\n",
        "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Estimating\"):\n",
        "            row = futures[future]\n",
        "            try:\n",
        "                d = future.result()\n",
        "                out_rows.append({\n",
        "                    \"county_fips\": row[\"county_fips_full\"],\n",
        "                    \"county\": row[\"county_display\"],\n",
        "                    \"predicted_credit_score\": d[\"estimated_credit_score\"],\n",
        "                    \"loan_confidence\": d[\"loan_confidence\"],\n",
        "                })\n",
        "            except Exception as e:\n",
        "                out_rows.append({\n",
        "                    \"county_fips\": row[\"county_fips_full\"],\n",
        "                    \"county\": row[\"county_display\"],\n",
        "                    \"predicted_credit_score\": None,\n",
        "                    \"loan_confidence\": None,\n",
        "                    \"error\": str(e),\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(out_rows)\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"Saved {len(df)} rows to {OUTPUT_CSV}\")\n",
        "\n",
        "    # For Colab: auto-download\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(OUTPUT_CSV)\n",
        "    except ImportError:\n",
        "        pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}